{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5625e444-f301-4e28-b9e4-142053513ab7",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
      "Requirement already satisfied: transformers in /databricks/python3/lib/python3.10/site-packages (4.31.0)\n",
      "Requirement already satisfied: openai in /databricks/python3/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: torch in /databricks/python3/lib/python3.10/site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (4.64.1)\n",
      "Requirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: datasets in /databricks/python3/lib/python3.10/site-packages (2.14.4)\n",
      "Requirement already satisfied: accelerate in /databricks/python3/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: matplotlib in /databricks/python3/lib/python3.10/site-packages (3.7.0)\n",
      "Collecting wandb\n",
      "  Using cached wandb-0.17.5-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: aiohttp in /databricks/python3/lib/python3.10/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in /databricks/python3/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /databricks/python3/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: networkx in /databricks/python3/lib/python3.10/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: cmake in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.27.6)\n",
      "Requirement already satisfied: lit in /databricks/python3/lib/python3.10/site-packages (from triton==2.0.0->torch) (17.0.2)\n",
      "Requirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /databricks/python3/lib/python3.10/site-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /databricks/python3/lib/python3.10/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: xxhash in /databricks/python3/lib/python3.10/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: multiprocess in /databricks/python3/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: psutil in /databricks/python3/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /databricks/python3/lib/python3.10/site-packages (from wandb) (8.0.4)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Using cached sentry_sdk-2.11.0-py2.py3-none-any.whl (303 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /databricks/python3/lib/python3.10/site-packages (from wandb) (4.24.0)\n",
      "Collecting setproctitle\n",
      "  Using cached setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from wandb) (3.1.27)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: setuptools in /databricks/python3/lib/python3.10/site-packages (from wandb) (65.6.3)\n",
      "Requirement already satisfied: platformdirs in /databricks/python3/lib/python3.10/site-packages (from wandb) (2.5.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Installing collected packages: setproctitle, sentry-sdk, docker-pycreds, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 sentry-sdk-2.11.0 setproctitle-1.3.3 wandb-0.17.5\n",
      "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "%pip install transformers openai torch tqdm numpy datasets accelerate matplotlib wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c31a9ade-c736-4970-82c5-05e0aa15a0d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-27 11:39:47,546] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import logging\n",
    "logging.basicConfig(level='ERROR')\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "# import openai\n",
    "import torch\n",
    "import zlib\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, AutoModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from eval import *\n",
    "from experiment_utils import *\n",
    "from model_utils import *\n",
    "from unlearning import *\n",
    "from accelerate import init_empty_weights, infer_auto_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da024cd4-fe38-45c0-a0c7-e6543561d7a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = 'EleutherAI/pythia-2.8b'\n",
    "output_dir = f\"experiment_output/{model}\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "experiment_args = ExperimentArgs(\n",
    "        model = model,\n",
    "        output_dir = output_dir,\n",
    "        # Directory in which to store models locally (to prevent having to download for each experiment)\n",
    "        model_dir_prefix = \"/dbfs/mnt/ds-data-apps/maris/base_models_dupe/\",\n",
    "        data = 'Cyproxius/GutenbergMIA_temporal',\n",
    "        data_name = 'GutenbergMIA',\n",
    "        length = 128,\n",
    "        threshold = 160\n",
    "    )\n",
    "# swj0419/WikiMIA\n",
    "# Cyproxius/GutenbergMIA_temporal\n",
    "# GutenbergMIA\n",
    "# NIH_ExPorterMIA_temporal\n",
    "# NIH_ExPorterMIA\n",
    "unlearning_args = UnlearningArgs(\n",
    "        lr=1e-6,\n",
    "        steps = 4,\n",
    "        batch_size = 10,\n",
    "        include_learning = False,\n",
    "        metric = 'All', # Choose from PPL, Min_K, Min_K++ or All\n",
    "        num_repeats = 1\n",
    "    )\n",
    "\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8c3de69-4190-420c-a88f-a2d6a14d8ced",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800d4420a7b040e692cf58aa7ef9fd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:27: UserWarning: This dataset can not be stored in DBFS because either `cache_dir` or the environment variable `HF_DATASETS_CACHE` is set to a non-DBFS path. If this cluster restarts, all saved dataset information will be lost.\n",
      "  warnings.warn(\n",
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:13: UserWarning: During large dataset downloads, there could be multiple progress bar widgets that can cause performance issues for your notebook or browser. To avoid these issues, use `datasets.utils.logging.disable_progress_bar()` to turn off the progress bars.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataloaders for all permutations\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Creating new dataloader\n",
      "Finished creating 16 dataloaders\n",
      "Running experiment for combination ('Adventure stories', 'Adventure stories')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]/Workspace/Users/maris.koopmans@rtl.nl/MIA-metric-thesisproject/src/eval.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(sentence).unsqueeze(0).to(gpu)\n",
      "\r1it [00:13, 13.45s/it]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PG_analysis_experiment = Experiment(experiment_args, unlearning_args)\n",
    "PG_analysis_experiment.run_gutenberg_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9154f463-d5ce-4ee8-b247-f565dde77a8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # lrs = [1e-7, 5e-6, 1e-6, 5e-5, 1e-5]\n",
    "# # TODO evaluate all datasets for these parameters with 5x repetitions\n",
    "# lrs = [1e-6]\n",
    "# steps = [4]\n",
    "# batch_sizes = [16]\n",
    "# # batch_sizes = [1,8,16]\n",
    "# experiment2 = Experiment(experiment_args, unlearning_args)\n",
    "# experiment2.run_gridsearch(lrs,steps,batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5676388e-6715-477b-b8ab-e75d0218066c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "graph_dir = output_dir + '/graphs/'\n",
    "if not os.path.exists(graph_dir):\n",
    "  os.makedirs(graph_dir)\n",
    "\n",
    "i = 1\n",
    "# Load JSON data from the file\n",
    "with open(f'{output_dir}/{experiment_args.data_name}_length{experiment_args.length}_grid_search_{i}.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "metrics = [metric for metric in data[0].keys() if metric != 'params']\n",
    "\n",
    "# Extract steps and corresponding MIM_AUC values\n",
    "steps = [entry['params']['steps'] for entry in data]\n",
    "\n",
    "all_metric_means = {metric: [entry[metric]['mean'] for entry in data] for metric in metrics}\n",
    "all_metric_stds = {metric: [entry[metric]['std'] for entry in data] for metric in metrics}\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "for metric, result in all_metric_means.items():\n",
    "    plt.errorbar(steps, result, yerr=all_metric_stds[metric], label=metric, marker='o')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Gradient ascent-based membership inference')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('MIM AUC')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "# plt.savefig(graph_dir+f'metrics_vs_ULsteps_grid_search_{i}.png')\n",
    "plt.savefig(graph_dir+f'{experiment_args.data_name}_length{experiment_args.length}_{unlearning_args.metric}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36185033-7152-4152-b6e1-dbe3b2bd725a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentence = \"The quick brown fox jumped over the lazy dog\"\n",
    "# sentence_encode = tokenizer.encode(sentence)\n",
    "# PPL = calculatePerplexity(sentence_encode, base_model, tokenizer, unlearning_args.device)\n",
    "# print(f\"PPL: {PPL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cbaca3d-1bc6-4b34-91d9-6c134f02f52e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "run.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
