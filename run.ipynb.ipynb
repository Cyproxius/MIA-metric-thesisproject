{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5625e444-f301-4e28-b9e4-142053513ab7",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "%pip install transformers openai torch tqdm numpy datasets accelerate matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c31a9ade-c736-4970-82c5-05e0aa15a0d2",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import logging\n",
    "logging.basicConfig(level='ERROR')\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "# import openai\n",
    "import torch\n",
    "import zlib\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, AutoModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from eval import *\n",
    "from args import *\n",
    "from model_utils import *\n",
    "from unlearning import *\n",
    "from accelerate import init_empty_weights, infer_auto_device_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4abc49bb-cf62-47ec-8171-bd6062c6511b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a616b139-8ed9-43c8-a2ca-c0667ba63a81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions for evaluating\n",
    "def inference(model1, model2, tokenizer1, tokenizer2, text, ex, modelname1, modelname2):\n",
    "    pred = {}\n",
    "\n",
    "    p1, all_prob, p1_likelihood = calculatePerplexity(text, model1, tokenizer1, gpu=model1.device)\n",
    "    p_lower, _, p_lower_likelihood = calculatePerplexity(text.lower(), model1, tokenizer1, gpu=model1.device)\n",
    "\n",
    "    p_ref, all_prob_ref, p_ref_likelihood = calculatePerplexity(text, model2, tokenizer2, gpu=model2.device)\n",
    "   \n",
    "    # ppl\n",
    "    pred[\"ppl\"] = p1\n",
    "    # Ratio of log ppl of large and small models\n",
    "    # pred[\"ppl/Ref_ppl (calibrate PPL to the reference model)\"] = p1_likelihood-p_ref_likelihood\n",
    "\n",
    "    print(f'p1: {p1}')\n",
    "    print(f'pref: {p_ref}')\n",
    "    MIM = (p1 - p_ref)/p_ref\n",
    "\n",
    "    print(f'MIM: {MIM}')\n",
    "    pred[\"MIM\"] = MIM\n",
    "\n",
    "    # Ratio of log ppl of lower-case and normal-case\n",
    "    pred[\"ppl/lowercase_ppl\"] = -(np.log(p_lower) / np.log(p1)).item()\n",
    "    # Ratio of log ppl of large and zlib\n",
    "    zlib_entropy = len(zlib.compress(bytes(text, 'utf-8')))\n",
    "    pred[\"ppl/zlib\"] = np.log(p1)/zlib_entropy\n",
    "    # min-k prob\n",
    "    for ratio in [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]:\n",
    "        k_length = int(len(all_prob)*ratio)\n",
    "        topk_prob = np.sort(all_prob)[:k_length]\n",
    "        pred[f\"Min_{ratio*100}% Prob\"] = -np.mean(topk_prob).item()\n",
    "\n",
    "    ex[\"pred\"] = pred\n",
    "    return ex\n",
    "\n",
    "def evaluate_data(test_data, model1, model2, tokenizer1, tokenizer2, col_name, modelname1, modelname2):\n",
    "    print(f\"all data size: {len(test_data)}\")\n",
    "    all_output = []\n",
    "    test_data = test_data\n",
    "    for ex in tqdm(test_data): \n",
    "        text = ex[col_name]\n",
    "        new_ex = inference(model1, model2, tokenizer1, tokenizer2, text, ex, modelname1, modelname2)\n",
    "        all_output.append(new_ex)\n",
    "    return all_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da024cd4-fe38-45c0-a0c7-e6543561d7a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_dir = \"experiment_output/pythia-2.8b\"\n",
    "\n",
    "experiment_args = ExperimentArgs(\n",
    "        target_model = 'EleutherAI/pythia-2.8b',\n",
    "        unlearn_model = 'EleutherAI/pythia-2.8b',\n",
    "        output_dir = output_dir,\n",
    "        key_name = 'input',\n",
    "        data = 'swj0419/WikiMIA',\n",
    "        length = 128,\n",
    "        save_loss = True\n",
    "    )\n",
    "\n",
    "unlearning_args = UnlearningArgs(\n",
    "        lr=1e-6,\n",
    "        epochs = 1,\n",
    "        col_name = \"input\",\n",
    "        save_model = True,\n",
    "        only_members = True,\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    )\n",
    "\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e702a53-746e-4ef2-b093-01717b4a2138",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load base model\n",
    "# model1, tokenizer1 = load_base_model(experiment_args.target_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbe65858-5123-4d59-93d3-447d4de321ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load unlearned model\n",
    "model2, tokenizer2 = load_unlearned_model(experiment_args, unlearning_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4372dab9-6881-4e32-ad98-22992e2eed0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if \"jsonl\" in experiment_args.data:\n",
    "  data = load_jsonl(f\"{experiment_args.data}\")\n",
    "else: # load data from huggingface\n",
    "  dataset = load_dataset(experiment_args.data, split=f\"WikiMIA_length{experiment_args.length}\")\n",
    "  data = convert_huggingface_data_to_list_dic(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "515474ae-e9ff-4c33-9211-89ea2ce383fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# out_text_model1 = generate_text(model1, tokenizer1, \"What is the diameter of the sun?\")\n",
    "# print(f\"Model 1 output: {out_text_model1}\\n\")\n",
    "out_text_model2 = generate_text(model2, tokenizer2, \"What is the diameter of the sun?\")\n",
    "print(f\"Model 2 output: {out_text_model2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57f1e69f-0b92-428b-b382-72e78ab59148",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_output = evaluate_data(data, model1, model2, tokenizer1, tokenizer2, experiment_args.key_name, experiment_args.target_model, experiment_args.unlearn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "337fae54-9d12-4644-9f62-0dbe937a8c29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig_fpr_tpr(all_output, experiment_args.output_dir)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "run.ipynb",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
