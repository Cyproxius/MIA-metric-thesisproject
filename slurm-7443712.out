Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: transformers in /home/mkoopmans/.local/lib/python3.11/site-packages (4.44.0)
Requirement already satisfied: torch in /home/mkoopmans/.local/lib/python3.11/site-packages (2.4.0)
Requirement already satisfied: tqdm in /home/mkoopmans/.local/lib/python3.11/site-packages (4.66.5)
Requirement already satisfied: numpy in /home/mkoopmans/.local/lib/python3.11/site-packages (1.26.4)
Requirement already satisfied: datasets in /home/mkoopmans/.local/lib/python3.11/site-packages (2.20.0)
Requirement already satisfied: accelerate in /home/mkoopmans/.local/lib/python3.11/site-packages (0.33.0)
Requirement already satisfied: matplotlib in /home/mkoopmans/.local/lib/python3.11/site-packages (3.9.1.post1)
Requirement already satisfied: scikit-learn in /home/mkoopmans/.local/lib/python3.11/site-packages (1.5.1)
Requirement already satisfied: filelock in /home/mkoopmans/.local/lib/python3.11/site-packages (from transformers) (3.15.4)
Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/mkoopmans/.local/lib/python3.11/site-packages (from transformers) (0.24.5)
Requirement already satisfied: packaging>=20.0 in /sw/arch/RHEL8/EB_production/2023/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers) (23.1)
Requirement already satisfied: pyyaml>=5.1 in /home/mkoopmans/.local/lib/python3.11/site-packages (from transformers) (6.0.2)
Requirement already satisfied: regex!=2019.12.17 in /home/mkoopmans/.local/lib/python3.11/site-packages (from transformers) (2024.7.24)
Requirement already satisfied: requests in /home/mkoopmans/.local/lib/python3.11/site-packages (from transformers) (2.32.3)
Requirement already satisfied: safetensors>=0.4.1 in /home/mkoopmans/.local/lib/python3.11/site-packages (from transformers) (0.4.4)
Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/mkoopmans/.local/lib/python3.11/site-packages (from transformers) (0.19.1)
Requirement already satisfied: typing-extensions>=4.8.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (4.12.2)
Requirement already satisfied: sympy in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (1.13.1)
Requirement already satisfied: networkx in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (3.3)
Requirement already satisfied: jinja2 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (3.1.4)
Requirement already satisfied: fsspec in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (2024.5.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (9.1.0.70)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (2.20.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (12.1.105)
Requirement already satisfied: triton==3.0.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from torch) (3.0.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mkoopmans/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)
Requirement already satisfied: pyarrow>=15.0.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from datasets) (17.0.0)
Requirement already satisfied: pyarrow-hotfix in /home/mkoopmans/.local/lib/python3.11/site-packages (from datasets) (0.6)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from datasets) (0.3.8)
Requirement already satisfied: pandas in /home/mkoopmans/.local/lib/python3.11/site-packages (from datasets) (2.2.2)
Requirement already satisfied: xxhash in /home/mkoopmans/.local/lib/python3.11/site-packages (from datasets) (3.4.1)
Requirement already satisfied: multiprocess in /home/mkoopmans/.local/lib/python3.11/site-packages (from datasets) (0.70.16)
Requirement already satisfied: aiohttp in /home/mkoopmans/.local/lib/python3.11/site-packages (from datasets) (3.10.3)
Requirement already satisfied: psutil in /home/mkoopmans/.local/lib/python3.11/site-packages (from accelerate) (6.0.0)
Requirement already satisfied: contourpy>=1.0.1 in /home/mkoopmans/.local/lib/python3.11/site-packages (from matplotlib) (1.2.1)
Requirement already satisfied: cycler>=0.10 in /home/mkoopmans/.local/lib/python3.11/site-packages (from matplotlib) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from matplotlib) (4.53.1)
Requirement already satisfied: kiwisolver>=1.3.1 in /home/mkoopmans/.local/lib/python3.11/site-packages (from matplotlib) (1.4.5)
Requirement already satisfied: pillow>=8 in /home/mkoopmans/.local/lib/python3.11/site-packages (from matplotlib) (10.4.0)
Requirement already satisfied: pyparsing>=2.3.1 in /home/mkoopmans/.local/lib/python3.11/site-packages (from matplotlib) (3.1.2)
Requirement already satisfied: python-dateutil>=2.7 in /home/mkoopmans/.local/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)
Requirement already satisfied: scipy>=1.6.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from scikit-learn) (1.14.0)
Requirement already satisfied: joblib>=1.2.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from scikit-learn) (1.4.2)
Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from scikit-learn) (3.5.0)
Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from aiohttp->datasets) (2.3.5)
Requirement already satisfied: aiosignal>=1.1.2 in /home/mkoopmans/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)
Requirement already satisfied: attrs>=17.3.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)
Requirement already satisfied: frozenlist>=1.1.1 in /home/mkoopmans/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)
Requirement already satisfied: multidict<7.0,>=4.5 in /home/mkoopmans/.local/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)
Requirement already satisfied: yarl<2.0,>=1.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)
Requirement already satisfied: six>=1.5 in /home/mkoopmans/.local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /home/mkoopmans/.local/lib/python3.11/site-packages (from requests->transformers) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /home/mkoopmans/.local/lib/python3.11/site-packages (from requests->transformers) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mkoopmans/.local/lib/python3.11/site-packages (from requests->transformers) (2.2.2)
Requirement already satisfied: certifi>=2017.4.17 in /home/mkoopmans/.local/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)
Requirement already satisfied: MarkupSafe>=2.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)
Requirement already satisfied: pytz>=2020.1 in /home/mkoopmans/.local/lib/python3.11/site-packages (from pandas->datasets) (2024.1)
Requirement already satisfied: tzdata>=2022.7 in /home/mkoopmans/.local/lib/python3.11/site-packages (from pandas->datasets) (2024.1)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mkoopmans/.local/lib/python3.11/site-packages (from sympy->torch) (1.3.0)

[notice] A new release of pip is available: 23.1.2 -> 24.2
[notice] To update, run: pip install --upgrade pip
DEVICE COUNT: 4
DEVICE COUNT: 4
DEVICE COUNT: 4
DEVICE COUNT: 4
/home/mkoopmans/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/home/mkoopmans/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/home/mkoopmans/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/home/mkoopmans/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
Accelerate device: cuda:0
Accelerate distributed type: DistributedType.FSDP
Accelerate use distributed: True
0it [00:00, ?it/s]Accelerate device: cuda:3
Accelerate distributed type: DistributedType.FSDP
Accelerate use distributed: True
0it [00:00, ?it/s]Accelerate device: cuda:1
Accelerate distributed type: DistributedType.FSDP
Accelerate use distributed: True
0it [00:00, ?it/s]Accelerate device: cuda:2
Accelerate distributed type: DistributedType.FSDP
Accelerate use distributed: True
0it [00:00, ?it/s]
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s][A
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s][A
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s][A
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s][A
Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  6.42it/s][A
Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  5.90it/s][A
Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:00,  5.80it/s][A
Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  7.76it/s][A
Loading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  7.35it/s]
[ALoading checkpoint shards:  33%|███▎      | 2/6 [00:00<00:00,  7.31it/s][A
Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  8.31it/s][A
Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  8.10it/s][A
Loading checkpoint shards:  50%|█████     | 3/6 [00:00<00:00,  7.95it/s][A
Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  8.53it/s][A
Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  8.58it/s][A
Loading checkpoint shards:  67%|██████▋   | 4/6 [00:00<00:00,  8.30it/s][A
Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  8.79it/s][A
Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  8.73it/s][A
Loading checkpoint shards:  83%|████████▎ | 5/6 [00:00<00:00,  8.52it/s][A
Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  9.00it/s][ALoading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.41it/s]

Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.85it/s][ALoading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.47it/s]

Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.71it/s][ALoading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.21it/s]
/home/mkoopmans/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/home/mkoopmans/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/home/mkoopmans/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(

Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:12,  2.52s/it][A
Loading checkpoint shards:  33%|███▎      | 2/6 [00:04<00:09,  2.46s/it][A
Loading checkpoint shards:  50%|█████     | 3/6 [00:07<00:07,  2.42s/it][A
Loading checkpoint shards:  67%|██████▋   | 4/6 [00:09<00:04,  2.38s/it][A
Loading checkpoint shards:  83%|████████▎ | 5/6 [00:12<00:02,  2.38s/it][A
Loading checkpoint shards: 100%|██████████| 6/6 [00:13<00:00,  2.12s/it][ALoading checkpoint shards: 100%|██████████| 6/6 [00:13<00:00,  2.27s/it]
/home/mkoopmans/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
0it [00:19, ?it/s]
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/mkoopmans/MIA-metric-thesisproject/run.py", line 88, in <module>
[rank0]:     perform_experiment(args, exp_args)
[rank0]:   File "/home/mkoopmans/MIA-metric-thesisproject/run.py", line 64, in perform_experiment
[rank0]:     experiment.run_experiment(unlearning_args)
[rank0]:   File "/gpfs/home3/mkoopmans/MIA-metric-thesisproject/experiment_utils.py", line 137, in run_experiment
[rank0]:     results_dict = self.experiment_loop(dataloader)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/gpfs/home3/mkoopmans/MIA-metric-thesisproject/experiment_utils.py", line 52, in experiment_loop
[rank0]:     unlearned_model, optimizer, batch_inputs = accelerator.prepare(unlearned_model, optimizer, batch_inputs)
[rank0]:                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/accelerate/accelerator.py", line 1311, in prepare
[rank0]:     result = tuple(
[rank0]:              ^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/accelerate/accelerator.py", line 1312, in <genexpr>
[rank0]:     self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
[rank0]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/accelerate/accelerator.py", line 1188, in _prepare_one
[rank0]:     return self.prepare_model(obj, device_placement=device_placement)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/accelerate/accelerator.py", line 1485, in prepare_model
[rank0]:     model = FSDP(model, **kwargs)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 483, in __init__
[rank0]:     _auto_wrap(
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/fsdp/_wrap_utils.py", line 102, in _auto_wrap
[rank0]:     _recursive_wrap(**recursive_wrap_kwargs, **root_kwargs)  # type: ignore[arg-type]
[rank0]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/fsdp/wrap.py", line 544, in _recursive_wrap
[rank0]:     wrapped_child, num_wrapped_params = _recursive_wrap(
[rank0]:                                         ^^^^^^^^^^^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/fsdp/wrap.py", line 544, in _recursive_wrap
[rank0]:     wrapped_child, num_wrapped_params = _recursive_wrap(
[rank0]:                                         ^^^^^^^^^^^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/fsdp/wrap.py", line 544, in _recursive_wrap
[rank0]:     wrapped_child, num_wrapped_params = _recursive_wrap(
[rank0]:                                         ^^^^^^^^^^^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/fsdp/wrap.py", line 562, in _recursive_wrap
[rank0]:     return _wrap(module, wrapper_cls, **kwargs), nonwrapped_numel
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/fsdp/wrap.py", line 491, in _wrap
[rank0]:     return wrapper_cls(module, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 509, in __init__
[rank0]:     _init_param_handle_from_module(
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/fsdp/_init_utils.py", line 587, in _init_param_handle_from_module
[rank0]:     state.compute_device = _get_compute_device(
[rank0]:                            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/fsdp/_init_utils.py", line 1050, in _get_compute_device
[rank0]:     raise ValueError(
[rank0]: ValueError: Inconsistent compute device and `device_id` on rank 0: cuda:1 vs cuda:0
[rank0]:[W811 16:43:40.604119773 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W0811 16:43:41.423000 23165980768064 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3410091 closing signal SIGTERM
W0811 16:43:41.423000 23165980768064 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3410092 closing signal SIGTERM
W0811 16:43:41.424000 23165980768064 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 3410093 closing signal SIGTERM
E0811 16:43:43.454000 23165980768064 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3410090) of binary: /sw/arch/RHEL8/EB_production/2023/software/Python/3.11.3-GCCcore-12.3.0/bin/python
Traceback (most recent call last):
  File "/home/mkoopmans/.local/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/mkoopmans/.local/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/home/mkoopmans/.local/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1093, in launch_command
    multi_gpu_launcher(args)
  File "/home/mkoopmans/.local/lib/python3.11/site-packages/accelerate/commands/launch.py", line 734, in multi_gpu_launcher
    distrib_run.run(args)
  File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mkoopmans/.local/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/mkoopmans/MIA-metric-thesisproject/run.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-08-11_16:43:41
  host      : gcn22.local.snellius.surf.nl
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3410090)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================

JOB STATISTICS
==============
Job ID: 7443712
Cluster: snellius
User/Group: mkoopmans/mkoopmans
State: RUNNING
Nodes: 1
Cores per node: 72
CPU Utilized: 00:01:29
CPU Efficiency: 2.38% of 01:02:24 core-walltime
Job Wall-clock time: 00:00:52
Memory Utilized: 4.71 GB
Memory Efficiency: 0.98% of 480.00 GB
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
